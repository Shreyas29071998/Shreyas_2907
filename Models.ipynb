{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c916802a-4fd3-4e62-8f55-93b5f64bbe1b",
   "metadata": {},
   "source": [
    "## ECommerce Recommendation System"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d099f4f-f3a7-4111-9bdf-757c75e3521a",
   "metadata": {},
   "source": [
    "### Aju Thomas: 48329426\n",
    "### Devarsh Rajesh Bende : 80060804\n",
    "### Dhruv Kumar Boothu : 24121668\n",
    "### Shreyas Subramanya : 41103539"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "111084ca-d871-4fa7-b026-cac639f66490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2781480 entries, 0 to 2781479\n",
      "Data columns (total 19 columns):\n",
      " #   Column        Dtype              \n",
      "---  ------        -----              \n",
      " 0   event_time    object             \n",
      " 1   event_type    object             \n",
      " 2   product_id    object             \n",
      " 3   brand         object             \n",
      " 4   price         object             \n",
      " 5   user_id       object             \n",
      " 6   user_session  object             \n",
      " 7   target        int64              \n",
      " 8   cat_0         object             \n",
      " 9   cat_1         object             \n",
      " 10  cat_2         object             \n",
      " 11  cat_3         object             \n",
      " 12  timestamp     datetime64[us, UTC]\n",
      " 13  ts_hour       int16              \n",
      " 14  ts_minute     int16              \n",
      " 15  ts_weekday    int16              \n",
      " 16  ts_day        int16              \n",
      " 17  ts_month      int16              \n",
      " 18  ts_year       int16              \n",
      "dtypes: datetime64[us, UTC](1), int16(6), int64(1), object(11)\n",
      "memory usage: 307.7+ MB\n",
      "None\n",
      "First 5 rows:\n",
      "                event_time event_type product_id   brand   price    user_id  \\\n",
      "0  2020-04-01 00:00:19 UTC       cart    5100328  xiaomi  117.12  635164513   \n",
      "1  2020-04-01 00:00:25 UTC       cart    5100328  xiaomi  117.12  635164513   \n",
      "2  2020-04-01 00:00:30 UTC       cart    5100328  xiaomi  117.12  635164513   \n",
      "3  2020-04-01 00:00:35 UTC       cart    5100328  xiaomi  117.12  635164513   \n",
      "4  2020-04-01 00:00:40 UTC       cart    5100328  xiaomi  117.12  635164513   \n",
      "\n",
      "                           user_session  target        cat_0   cat_1 cat_2  \\\n",
      "0  c40d1b96-90aa-4cee-b9aa-9475d9c4f17f       0  electronics  clocks    NA   \n",
      "1  c40d1b96-90aa-4cee-b9aa-9475d9c4f17f       0  electronics  clocks    NA   \n",
      "2  c40d1b96-90aa-4cee-b9aa-9475d9c4f17f       0  electronics  clocks    NA   \n",
      "3  c40d1b96-90aa-4cee-b9aa-9475d9c4f17f       0  electronics  clocks    NA   \n",
      "4  c40d1b96-90aa-4cee-b9aa-9475d9c4f17f       0  electronics  clocks    NA   \n",
      "\n",
      "  cat_3                 timestamp  ts_hour  ts_minute  ts_weekday  ts_day  \\\n",
      "0    NA 2020-04-01 00:00:19+00:00        0          0           2       1   \n",
      "1    NA 2020-04-01 00:00:25+00:00        0          0           2       1   \n",
      "2    NA 2020-04-01 00:00:30+00:00        0          0           2       1   \n",
      "3    NA 2020-04-01 00:00:35+00:00        0          0           2       1   \n",
      "4    NA 2020-04-01 00:00:40+00:00        0          0           2       1   \n",
      "\n",
      "   ts_month  ts_year  \n",
      "0         4     2020  \n",
      "1         4     2020  \n",
      "2         4     2020  \n",
      "3         4     2020  \n",
      "4         4     2020  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import random\n",
    "\n",
    "# 1. Data Loading (Using pyarrow)\n",
    "df = pd.read_parquet('/Users/Bobby/Documents/ML Project/test.parquet', engine='pyarrow')  \n",
    "\n",
    "#2. Display basic information about the dataset\n",
    "print(df.info())\n",
    "\n",
    "#Displaying the first 5 rows of the DataFrame:\n",
    "\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a386349b-50b5-4dc4-93d4-24e49e9ea3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 19 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   event_time    10000 non-null  object             \n",
      " 1   event_type    10000 non-null  object             \n",
      " 2   product_id    10000 non-null  object             \n",
      " 3   brand         10000 non-null  object             \n",
      " 4   price         10000 non-null  object             \n",
      " 5   user_id       10000 non-null  object             \n",
      " 6   user_session  10000 non-null  object             \n",
      " 7   target        10000 non-null  int64              \n",
      " 8   cat_0         10000 non-null  object             \n",
      " 9   cat_1         10000 non-null  object             \n",
      " 10  cat_2         10000 non-null  object             \n",
      " 11  cat_3         10000 non-null  object             \n",
      " 12  timestamp     10000 non-null  datetime64[us, UTC]\n",
      " 13  ts_hour       10000 non-null  int16              \n",
      " 14  ts_minute     10000 non-null  int16              \n",
      " 15  ts_weekday    10000 non-null  int16              \n",
      " 16  ts_day        10000 non-null  int16              \n",
      " 17  ts_month      10000 non-null  int16              \n",
      " 18  ts_year       10000 non-null  int16              \n",
      "dtypes: datetime64[us, UTC](1), int16(6), int64(1), object(11)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "First 5 rows:\n",
      "                event_time event_type product_id      brand   price  \\\n",
      "0  2020-04-29 11:04:45 UTC       cart   12202118  novatrack  100.13   \n",
      "1  2020-04-20 14:33:02 UTC       cart    4804056      apple  165.77   \n",
      "2  2020-04-19 18:14:29 UTC       cart    4201154   atlantic  223.92   \n",
      "3  2020-04-26 06:32:31 UTC       cart    2502287       asel    77.2   \n",
      "4  2020-04-29 19:31:49 UTC       cart    1005160     xiaomi  183.51   \n",
      "\n",
      "     user_id                          user_session  target         cat_0  \\\n",
      "0  636275485  1629daf6-5528-4053-a4cc-06d8f1320729       0    appliances   \n",
      "1  548899534  86f72fa2-295f-4c2b-a86a-2de4fb75e554       0         sport   \n",
      "2  570674453  c624a947-5aac-4f88-a530-e0e05ff6ac1b       0    appliances   \n",
      "3  517471582  b1d49f3f-ee9d-4623-9e0c-cc778da246c2       0    appliances   \n",
      "4  640184126  e52bab40-4ae4-4fed-8e24-a1626be22355       0  construction   \n",
      "\n",
      "         cat_1            cat_2 cat_3                 timestamp  ts_hour  \\\n",
      "0      kitchen           toster    NA 2020-04-29 11:04:45+00:00       11   \n",
      "1      bicycle               NA    NA 2020-04-20 14:33:02+00:00       14   \n",
      "2  environment  air_conditioner    NA 2020-04-19 18:14:29+00:00       18   \n",
      "3      kitchen             oven    NA 2020-04-26 06:32:31+00:00        6   \n",
      "4        tools            light    NA 2020-04-29 19:31:49+00:00       19   \n",
      "\n",
      "   ts_minute  ts_weekday  ts_day  ts_month  ts_year  \n",
      "0          4           2      29         4     2020  \n",
      "1         33           0      20         4     2020  \n",
      "2         14           6      19         4     2020  \n",
      "3         32           6      26         4     2020  \n",
      "4         31           2      29         4     2020  \n"
     ]
    }
   ],
   "source": [
    "# 2. Sampling\n",
    "sample_df = df.sample(n=10000, random_state=42)\n",
    "sample_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#3. Display basic information about the dataset\n",
    "print(sample_df.info())\n",
    "#Displaying the first 5 rows of the sampled DataFrame:\n",
    "print(\"First 5 rows:\")\n",
    "print(sample_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d2c1c86-5180-45e4-b251-8c04866a300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Data Preprocessing\n",
    "sample_df['brand'] = sample_df['brand'].astype(str).str.lower()\n",
    "sample_df['cat_0'] = sample_df['cat_0'].astype(str).str.lower()\n",
    "sample_df['cat_1'] = sample_df['cat_1'].astype(str).str.lower()\n",
    "sample_df['cat_2'] = sample_df['cat_2'].astype(str).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48d23c7-4df8-4035-816b-4e12ccf6988a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your search keyword:  toster\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendation 1:\n",
      "  Product ID: 12202118\n",
      "  Brand: novatrack\n",
      "  Price: 100.13\n",
      "  Category 0: appliances\n",
      "  Category 1: kitchen\n",
      "  Category 2: toster\n",
      "  Product ID: 12202118\n",
      "  Brand: novatrack\n",
      "  Price: 100.13\n",
      "  Category 0: appliances\n",
      "  Category 1: kitchen\n",
      "  Category 2: toster\n",
      "\n",
      "Recommendation 2:\n",
      "  Product ID: 100197355\n",
      "  Brand: forward\n",
      "  Price: 157.02\n",
      "  Category 0: appliances\n",
      "  Category 1: kitchen\n",
      "  Category 2: toster\n",
      "  Product ID: 100056116\n",
      "  Brand: forward\n",
      "  Price: 105.54\n",
      "  Category 0: appliances\n",
      "  Category 1: kitchen\n",
      "  Category 2: toster\n",
      "  Product ID: 100197355\n",
      "  Brand: forward\n",
      "  Price: 157.02\n",
      "  Category 0: appliances\n",
      "  Category 1: kitchen\n",
      "  Category 2: toster\n",
      "  Product ID: 100056590\n",
      "  Brand: forward\n",
      "  Price: 267.7\n",
      "  Category 0: appliances\n",
      "  Category 1: kitchen\n",
      "  Category 2: toster\n",
      "\n",
      "Recommendation 3:\n",
      "  Product ID: 12202336\n",
      "  Brand: na\n",
      "  Price: 77.22\n",
      "  Category 0: appliances\n",
      "  Category 1: kitchen\n",
      "  Category 2: toster\n",
      "  Product ID: 100027737\n",
      "  Brand: na\n",
      "  Price: 154.44\n",
      "  Category 0: appliances\n",
      "  Category 1: kitchen\n",
      "  Category 2: toster\n",
      "  Product ID: 12202336\n",
      "  Brand: na\n",
      "  Price: 76.96\n",
      "  Category 0: appliances\n",
      "  Category 1: kitchen\n",
      "  Category 2: toster\n",
      "  Product ID: 11900014\n",
      "  Brand: na\n",
      "  Price: 96.12\n",
      "  Category 0: appliances\n",
      "  Category 1: kitchen\n",
      "  Category 2: toster\n",
      "  Product ID: 100210323\n",
      "  Brand: na\n",
      "  Price: 92.64\n",
      "  Category 0: appliances\n",
      "  Category 1: kitchen\n",
      "  Category 2: toster\n"
     ]
    }
   ],
   "source": [
    "# Rule-based recommendation engine\n",
    "# 5. Feature Encoding\n",
    "# Create separate binarizers for each column\n",
    "brand_mlb = MultiLabelBinarizer()\n",
    "cat0_mlb = MultiLabelBinarizer()\n",
    "cat1_mlb = MultiLabelBinarizer()\n",
    "cat2_mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit and transform each column separately \n",
    "encoded_brand = brand_mlb.fit_transform(sample_df['brand'].values.reshape(-1, 1))\n",
    "encoded_cat0 = cat0_mlb.fit_transform(sample_df['cat_0'].values.reshape(-1, 1))\n",
    "encoded_cat1 = cat1_mlb.fit_transform(sample_df['cat_1'].values.reshape(-1, 1))\n",
    "encoded_cat2 = cat2_mlb.fit_transform(sample_df['cat_2'].values.reshape(-1, 1))\n",
    "\n",
    "# Create separate DataFrames for each encoded column using the correct binarizer\n",
    "encoded_brand_df = pd.DataFrame(encoded_brand, columns=[f\"brand_{c}\" for c in brand_mlb.classes_], index=sample_df.index)\n",
    "encoded_cat0_df = pd.DataFrame(encoded_cat0, columns=[f\"cat_0_{c}\" for c in cat0_mlb.classes_], index=sample_df.index)\n",
    "encoded_cat1_df = pd.DataFrame(encoded_cat1, columns=[f\"cat_1_{c}\" for c in cat1_mlb.classes_], index=sample_df.index)\n",
    "encoded_cat2_df = pd.DataFrame(encoded_cat2, columns=[f\"cat_2_{c}\" for c in cat2_mlb.classes_], index=sample_df.index)\n",
    "\n",
    "# Combine all encoded features\n",
    "encoded_df = pd.concat([encoded_brand_df, encoded_cat0_df, encoded_cat1_df, encoded_cat2_df], axis=1)\n",
    "\n",
    "# Combine with original dataframe \n",
    "sample_df = sample_df.join(encoded_df)\n",
    "\n",
    "# 6. Recommendation Function\n",
    "def recommend_items(keyword, df=sample_df, num_recs=5):\n",
    "    relevant_cols = ['brand', 'cat_0', 'cat_1', 'cat_2'] + list(encoded_df.columns)\n",
    "\n",
    "    # Filter relevant rows based on keyword\n",
    "    filtered_df = df[df[relevant_cols].apply(lambda row: keyword in row.values, axis=1)]\n",
    "\n",
    "    recommendations = []\n",
    "    for brand in filtered_df['brand'].unique():\n",
    "        for cat1 in filtered_df[filtered_df['brand'] == brand]['cat_1'].unique():\n",
    "            for cat2 in filtered_df[(filtered_df['brand'] == brand) & (filtered_df['cat_1'] == cat1)]['cat_2'].unique():\n",
    "                group = filtered_df[(filtered_df['brand'] == brand) & \n",
    "                                   (filtered_df['cat_1'] == cat1) & \n",
    "                                   (filtered_df['cat_2'] == cat2)]\n",
    "\n",
    "                # Sample and get relevant columns as dictionaries\n",
    "                recs = group.sample(min(num_recs, len(group)))[['product_id', 'brand', 'price', 'cat_0', 'cat_1', 'cat_2']].to_dict(orient='records')\n",
    "                recommendations.append(recs)\n",
    "\n",
    "    return recommendations[:3]  # Get top 3 recommendations\n",
    "# 7. User Interaction\n",
    "keyword = input(\"Enter your search keyword: \")\n",
    "recommendations = recommend_items(keyword.lower())\n",
    "\n",
    "if recommendations:\n",
    "    for i, rec_list in enumerate(recommendations):\n",
    "        print(f\"\\nRecommendation {i+1}:\")\n",
    "        for item in rec_list:\n",
    "            print(f\"  Product ID: {item['product_id']}\")\n",
    "            print(f\"  Brand: {item['brand']}\")\n",
    "            print(f\"  Price: {item['price']}\")\n",
    "            print(f\"  Category 0: {item['cat_0']}\")\n",
    "            print(f\"  Category 1: {item['cat_1']}\")\n",
    "            print(f\"  Category 2: {item['cat_2']}\")\n",
    "else:\n",
    "    print(\"No recommendations found for this keyword.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5172177c-4b75-4077-9aa4-155654fc0d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your search keyword:  headphone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendation 1:\n",
      "  Product ID: 100051366\n",
      "  Brand: hp\n",
      "  Price: 820.87\n",
      "  Category 0: electronics\n",
      "  Category 1: audio\n",
      "  Category 2: headphone\n",
      "\n",
      "Recommendation 2:\n",
      "  Product ID: 100170577\n",
      "  Brand: hp\n",
      "  Price: 306.06\n",
      "  Category 0: electronics\n",
      "  Category 1: audio\n",
      "  Category 2: headphone\n",
      "\n",
      "Recommendation 3:\n",
      "  Product ID: 100170834\n",
      "  Brand: hp\n",
      "  Price: 247.08\n",
      "  Category 0: electronics\n",
      "  Category 1: audio\n",
      "  Category 2: headphone\n",
      "\n",
      "Recommendation 4:\n",
      "  Product ID: 100055405\n",
      "  Brand: asus\n",
      "  Price: 592.01\n",
      "  Category 0: electronics\n",
      "  Category 1: audio\n",
      "  Category 2: headphone\n",
      "\n",
      "Recommendation 5:\n",
      "  Product ID: 100003338\n",
      "  Brand: asus\n",
      "  Price: 849.42\n",
      "  Category 0: electronics\n",
      "  Category 1: audio\n",
      "  Category 2: headphone\n"
     ]
    }
   ],
   "source": [
    "# Content-Based Filtering Recommendatoin\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. Feature Selection and Encoding (Modify as needed for your specific features)\n",
    "relevant_cols = ['brand', 'cat_0', 'cat_1', 'cat_2']\n",
    "\n",
    "# Combine all features into one string per product for TF-IDF\n",
    "sample_df['content'] = sample_df[relevant_cols].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# 2. TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(sample_df['content'])\n",
    "\n",
    "# 3. Cosine Similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "\n",
    "# 4. Recommendation Function\n",
    "def recommend_items(keyword, df=sample_df, cosine_sim_matrix=cosine_sim, num_recs=5):\n",
    "    relevant_cols = ['brand', 'cat_0', 'cat_1', 'cat_2']\n",
    "    filtered_df = df[df[relevant_cols].apply(lambda row: keyword in row.values, axis=1)]\n",
    "\n",
    "    recommendations = []\n",
    "    for idx in filtered_df.index:\n",
    "        # Get the indices of the most similar items\n",
    "        sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1:num_recs+1]  # Exclude the item itself\n",
    "\n",
    "        # Get the product IDs of the most similar items\n",
    "        item_indices = [i[0] for i in sim_scores]\n",
    "        recs = df.iloc[item_indices][['product_id', 'brand', 'price', 'cat_0', 'cat_1', 'cat_2']].to_dict(orient='records')\n",
    "        recommendations.append(recs)\n",
    "\n",
    "    # Flatten and de-duplicate recommendations\n",
    "    flattened_recs = [item for sublist in recommendations for item in sublist]\n",
    "    seen = set()\n",
    "    unique_recs = []\n",
    "    for item in flattened_recs:\n",
    "        if item['product_id'] not in seen:\n",
    "            seen.add(item['product_id'])\n",
    "            unique_recs.append(item)\n",
    "\n",
    "    return unique_recs[:5]  # Get top 5 unique recommendations\n",
    "\n",
    "# 5. User Interaction (Example)\n",
    "keyword = input(\"Enter your search keyword: \")\n",
    "recommendations = recommend_items(keyword.lower())\n",
    "\n",
    "if recommendations:\n",
    "    for i, rec in enumerate(recommendations):\n",
    "        print(f\"\\nRecommendation {i+1}:\")\n",
    "        print(f\"  Product ID: {rec['product_id']}\")\n",
    "        print(f\"  Brand: {rec['brand']}\")\n",
    "        print(f\"  Price: {rec['price']}\")\n",
    "        print(f\"  Category 0: {rec['cat_0']}\")\n",
    "        print(f\"  Category 1: {rec['cat_1']}\")\n",
    "        print(f\"  Category 2: {rec['cat_2']}\")\n",
    "else:\n",
    "    print(\"No recommendations found for this keyword.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "335045d0-ae57-4172-b35e-262a8136696f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 User ID Occurrences:\n",
      "user_id\n",
      "592816742    5\n",
      "616119853    3\n",
      "561804169    3\n",
      "640663684    3\n",
      "640529380    3\n",
      "635361405    2\n",
      "576947743    2\n",
      "612892292    2\n",
      "543176993    2\n",
      "635786036    2\n",
      "512746568    2\n",
      "615564020    2\n",
      "525119354    2\n",
      "596815932    2\n",
      "567389498    2\n",
      "525164158    2\n",
      "575954873    2\n",
      "637519148    2\n",
      "601602231    2\n",
      "536908726    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each user ID for further Recommendation\n",
    "user_id_counts = sample_df['user_id'].value_counts()\n",
    "\n",
    "# Get the top 20 user IDs and their counts\n",
    "top_10_user_ids = user_id_counts.head(20)  # Use head(10) to get the top 10\n",
    "\n",
    "# Display the top  user IDs and their counts\n",
    "print(\"Top 20 User ID Occurrences:\")\n",
    "print(top_10_user_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64dd02a9-a9a3-4820-be1b-0a30c66f0c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter user ID:  616119853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Recommendations for User 616119853:\n",
      "\n",
      "Recommendation 1:\n",
      "  Product ID: 100068493\n",
      "  Brand: samsung\n",
      "  Price: 310.15\n",
      "  Category 0: construction\n",
      "  Category 1: tools\n",
      "  Category 2: light\n",
      "\n",
      "Recommendation 2:\n",
      "  Product ID: 1005115\n",
      "  Brand: apple\n",
      "  Price: 925.88\n",
      "  Category 0: construction\n",
      "  Category 1: tools\n",
      "  Category 2: light\n",
      "\n",
      "Recommendation 3:\n",
      "  Product ID: 1005212\n",
      "  Brand: samsung\n",
      "  Price: 168.32\n",
      "  Category 0: construction\n",
      "  Category 1: tools\n",
      "  Category 2: light\n",
      "\n",
      "Recommendation 4:\n",
      "  Product ID: 1005212\n",
      "  Brand: samsung\n",
      "  Price: 167.8\n",
      "  Category 0: construction\n",
      "  Category 1: tools\n",
      "  Category 2: light\n",
      "\n",
      "Recommendation 5:\n",
      "  Product ID: 1005212\n",
      "  Brand: samsung\n",
      "  Price: 169.35\n",
      "  Category 0: construction\n",
      "  Category 1: tools\n",
      "  Category 2: light\n"
     ]
    }
   ],
   "source": [
    "#Collaborative Filtering\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# 1. Create User-Item Interaction Matrix\n",
    "user_item_matrix = sample_df.pivot_table(index='user_id', columns='product_id', values='target', fill_value=0)\n",
    "\n",
    "# Convert to sparse CSR matrix for efficiency\n",
    "user_item_sparse = csr_matrix(user_item_matrix.values)\n",
    "\n",
    "# 2. Matrix Factorization (SVD)\n",
    "num_factors = 10  # Adjust the number of latent factors as needed\n",
    "U, sigma, Vt = svds(user_item_sparse, k=num_factors)\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "# 3. Predictions\n",
    "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
    "predicted_ratings = pd.DataFrame(predicted_ratings, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "# 4. Recommendation Function (Modified)\n",
    "def recommend_items(user_id, df=predicted_ratings, num_recs=5):\n",
    "    user_ratings = df.loc[user_id].sort_values(ascending=False)\n",
    "    \n",
    "    # Exclude items the user has already interacted with and limit to top 5\n",
    "    recommendations = user_ratings[user_ratings > 0].head(num_recs)\n",
    "\n",
    "    # Retrieve product details from the original DataFrame\n",
    "    product_details = sample_df[sample_df['product_id'].isin(recommendations.index)][['product_id', 'brand', 'price', 'cat_0', 'cat_1', 'cat_2']]\n",
    "    return product_details.to_dict(orient='records')  # Return the top 5 recommendations\n",
    "\n",
    "# 5. User Interaction (Example with Top 5 Limit)\n",
    "# Get user input\n",
    "user_id = input(\"Enter user ID: \") \n",
    "\n",
    "# Validate user ID and make recommendations\n",
    "if user_id in user_item_matrix.index:\n",
    "    recommendations = recommend_items(user_id)  \n",
    "    \n",
    "    # Print only top 5 recommendations\n",
    "    num_recommendations_to_print = min(5, len(recommendations)) \n",
    "    \n",
    "    if num_recommendations_to_print > 0:\n",
    "        print(f\"\\nTop {num_recommendations_to_print} Recommendations for User {user_id}:\")\n",
    "        for i, rec in enumerate(recommendations[:num_recommendations_to_print]):\n",
    "            print(f\"\\nRecommendation {i+1}:\")\n",
    "            print(f\"  Product ID: {rec['product_id']}\")\n",
    "            print(f\"  Brand: {rec['brand']}\")\n",
    "            print(f\"  Price: {rec['price']}\")\n",
    "            print(f\"  Category 0: {rec['cat_0']}\")\n",
    "            print(f\"  Category 1: {rec['cat_1']}\")\n",
    "            print(f\"  Category 2: {rec['cat_2']}\")\n",
    "    else:\n",
    "        print(f\"No recommendations found for user {user_id}.\")\n",
    "else:\n",
    "    print(f\"User ID {user_id} not found in the dataset.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3ca26ba-85d1-4de7-9853-4bef3d2adc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter user ID:  543176993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Recommendations for User 543176993:\n",
      "\n",
      "Recommendation 1:\n",
      "  Product ID: 1005160\n",
      "  Brand: xiaomi\n",
      "  Price: 183.51\n",
      "  Category 0: construction\n",
      "  Category 1: tools\n",
      "  Category 2: light\n",
      "\n",
      "Recommendation 2:\n",
      "  Product ID: 1002544\n",
      "  Brand: apple\n",
      "  Price: 407.07\n",
      "  Category 0: construction\n",
      "  Category 1: tools\n",
      "  Category 2: light\n",
      "\n",
      "Recommendation 3:\n",
      "  Product ID: 100068493\n",
      "  Brand: samsung\n",
      "  Price: 310.15\n",
      "  Category 0: construction\n",
      "  Category 1: tools\n",
      "  Category 2: light\n",
      "\n",
      "Recommendation 4:\n",
      "  Product ID: 1005115\n",
      "  Brand: apple\n",
      "  Price: 925.88\n",
      "  Category 0: construction\n",
      "  Category 1: tools\n",
      "  Category 2: light\n",
      "\n",
      "Recommendation 5:\n",
      "  Product ID: 1004836\n",
      "  Brand: samsung\n",
      "  Price: 208.47\n",
      "  Category 0: construction\n",
      "  Category 1: tools\n",
      "  Category 2: light\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Recommendation system\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. Content-Based Filtering \n",
    "relevant_cols = ['brand', 'cat_0', 'cat_1', 'cat_2']\n",
    "sample_df['content'] = sample_df[relevant_cols].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(sample_df['content'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# 2. Collaborative Filtering (Similar to previous response)\n",
    "user_item_matrix = sample_df.pivot_table(index='user_id', columns='product_id', values='target', fill_value=0)\n",
    "user_item_sparse = csr_matrix(user_item_matrix.values)\n",
    "\n",
    "num_factors = 10\n",
    "U, sigma, Vt = svds(user_item_sparse, k=num_factors)\n",
    "sigma = np.diag(sigma)\n",
    "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
    "predicted_ratings = pd.DataFrame(predicted_ratings, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "# 3. Hybrid Recommendation Function\n",
    "def recommend_items_hybrid(user_id, df=sample_df, num_recs=5, content_weight=0.5, collab_weight=0.5):\n",
    "    user_interactions = sample_df[sample_df['user_id'] == user_id]['product_id']\n",
    "    \n",
    "    # Content-based recommendations\n",
    "    content_recs = []\n",
    "    for item_id in user_interactions:\n",
    "        sim_scores = list(enumerate(cosine_sim[df[df['product_id'] == item_id].index[0]]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1:num_recs+1]  # Exclude the item itself\n",
    "        content_recs.extend([(df['product_id'][i], s) for i, s in sim_scores])\n",
    "    \n",
    "    # Collaborative filtering recommendations\n",
    "    collab_recs = predicted_ratings.loc[user_id].sort_values(ascending=False)[:num_recs].index.tolist()\n",
    "\n",
    "    # Combine and score recommendations\n",
    "    all_recs = content_recs + [(rec, 1.0) for rec in collab_recs] # Assign collab score of 1.0\n",
    "    scored_recs = {}\n",
    "    for item, score in all_recs:\n",
    "        scored_recs[item] = scored_recs.get(item, 0) + score * content_weight  # Weighted average\n",
    "        if item in collab_recs:  \n",
    "            scored_recs[item] += collab_weight  # Add extra weight for collaborative filtering\n",
    "\n",
    "    # Sort by score and get product details\n",
    "    top_recs = sorted(scored_recs.items(), key=lambda x: x[1], reverse=True)[:num_recs]\n",
    "    product_details = sample_df[sample_df['product_id'].isin([rec[0] for rec in top_recs])][['product_id', 'brand', 'price', 'cat_0', 'cat_1', 'cat_2']].to_dict(orient='records')\n",
    "\n",
    "    return product_details\n",
    "\n",
    "# 4. User Interaction (Example with Top 5 Limit)\n",
    "user_id = input(\"Enter user ID: \")\n",
    "if user_id in user_item_matrix.index:\n",
    "    recommendations = recommend_items(user_id)  \n",
    "    \n",
    "    # Print only top 5 recommendations\n",
    "    num_recommendations_to_print = min(5, len(recommendations)) \n",
    "    \n",
    "    if num_recommendations_to_print > 0:\n",
    "        print(f\"\\nTop {num_recommendations_to_print} Recommendations for User {user_id}:\")\n",
    "        for i, rec in enumerate(recommendations[:num_recommendations_to_print]):\n",
    "            print(f\"\\nRecommendation {i+1}:\")\n",
    "            print(f\"  Product ID: {rec['product_id']}\")\n",
    "            print(f\"  Brand: {rec['brand']}\")\n",
    "            print(f\"  Price: {rec['price']}\")\n",
    "            print(f\"  Category 0: {rec['cat_0']}\")\n",
    "            print(f\"  Category 1: {rec['cat_1']}\")\n",
    "            print(f\"  Category 2: {rec['cat_2']}\")\n",
    "    else:\n",
    "        print(f\"No recommendations found for user {user_id}.\")\n",
    "else:\n",
    "    print(f\"User ID {user_id} not found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5ec70-3a10-41af-8eaa-60b0a9f27ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
